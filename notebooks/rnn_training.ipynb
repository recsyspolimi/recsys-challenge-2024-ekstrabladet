{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 00:33:08.143482: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 00:33:08.207859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 00:33:09.298957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.random.set_seed(seed)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 3066.15 MB\n",
      "Memory usage after optimization is: 842.00 MB\n",
      "Decreased by 72.5%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 259)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>premium</th><th>weekday</th><th>category</th><th>hour_group</th><th>read_time</th><th>scroll_percentage</th><th>topics_0</th><th>topics_1</th><th>topics_2</th><th>topics_3</th><th>topics_4</th><th>topics_5</th><th>topics_6</th><th>topics_7</th><th>topics_8</th><th>topics_9</th><th>topics_10</th><th>topics_11</th><th>topics_12</th><th>topics_13</th><th>topics_14</th><th>topics_15</th><th>topics_16</th><th>topics_17</th><th>topics_18</th><th>topics_19</th><th>topics_20</th><th>topics_21</th><th>topics_22</th><th>topics_23</th><th>topics_24</th><th>topics_25</th><th>topics_26</th><th>topics_27</th><th>topics_28</th><th>topics_29</th><th>&hellip;</th><th>subcategory_137</th><th>subcategory_138</th><th>subcategory_139</th><th>subcategory_140</th><th>subcategory_141</th><th>subcategory_142</th><th>subcategory_143</th><th>subcategory_144</th><th>subcategory_145</th><th>subcategory_146</th><th>subcategory_147</th><th>subcategory_148</th><th>subcategory_149</th><th>subcategory_150</th><th>subcategory_151</th><th>subcategory_152</th><th>subcategory_153</th><th>subcategory_154</th><th>subcategory_155</th><th>subcategory_156</th><th>subcategory_157</th><th>subcategory_158</th><th>subcategory_159</th><th>subcategory_160</th><th>subcategory_161</th><th>subcategory_162</th><th>subcategory_163</th><th>subcategory_164</th><th>subcategory_165</th><th>subcategory_166</th><th>subcategory_167</th><th>subcategory_168</th><th>subcategory_169</th><th>subcategory_170</th><th>subcategory_171</th><th>subcategory_172</th><th>subcategory_173</th></tr><tr><td>u32</td><td>list[i8]</td><td>list[i8]</td><td>list[u8]</td><td>list[i8]</td><td>list[f32]</td><td>list[f32]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>&hellip;</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td><td>list[i8]</td></tr></thead><tbody><tr><td>377904</td><td>[0, 0, … 0]</td><td>[4, 4, … 3]</td><td>[4, 4, … 7]</td><td>[4, 4, … 3]</td><td>[6.0, 53.0, … 34.0]</td><td>[29.0, 100.0, … 44.0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 1]</td><td>[1, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[1, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 1]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 1]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>&hellip;</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 259)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ premium    ┆ weekday   ┆ category  ┆ … ┆ subcatego ┆ subcatego ┆ subcatego ┆ subcatego │\n",
       "│ ---     ┆ ---        ┆ ---       ┆ ---       ┆   ┆ ry_170    ┆ ry_171    ┆ ry_172    ┆ ry_173    │\n",
       "│ u32     ┆ list[i8]   ┆ list[i8]  ┆ list[u8]  ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│         ┆            ┆           ┆           ┆   ┆ list[i8]  ┆ list[i8]  ┆ list[i8]  ┆ list[i8]  │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 377904  ┆ [0, 0, …   ┆ [4, 4, …  ┆ [4, 4, …  ┆ … ┆ [0, 0, …  ┆ [0, 0, …  ┆ [0, 0, …  ┆ [0, 0, …  │\n",
       "│         ┆ 0]         ┆ 3]        ┆ 7]        ┆   ┆ 0]        ┆ 0]        ┆ 0]        ┆ 0]        │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polimi.utils.tf_models import TemporalHistorySequenceModel, TemporalHistoryClassificationModel\n",
    "from polimi.utils._polars import reduce_polars_df_memory_size\n",
    "\n",
    "history = pl.read_parquet('/home/ubuntu/dataset/ebnerd_small/train/history.parquet')\n",
    "behaviors = pl.read_parquet('/home/ubuntu/dataset/ebnerd_small/train/behaviors.parquet')\n",
    "articles = pl.read_parquet('/home/ubuntu/dataset/ebnerd_small/articles.parquet')\n",
    "\n",
    "topics = articles['topics'].explode().unique().drop_nans().drop_nulls().sort().to_frame().with_row_index()\n",
    "category = articles['category'].unique().drop_nans().drop_nulls().sort().to_frame().with_row_index(offset=1)\n",
    "subcategory = articles['subcategory'].explode().unique().drop_nans().drop_nulls().sort().to_frame().with_row_index()\n",
    "mask = 0\n",
    "\n",
    "articles = articles.select(['article_id', 'category', 'subcategory', 'premium', 'topics'])\\\n",
    "    .with_columns(\n",
    "        pl.col('topics').fill_null(pl.lit([])),\n",
    "        pl.col('subcategory').fill_null(pl.lit([]))\n",
    "    )\\\n",
    "    .with_columns(\n",
    "        pl.col('topics').list.eval(pl.element().replace(topics['topics'], topics['index'], default=None)).list.drop_nulls(),\n",
    "        pl.col('category').replace(category['category'], category['index'], default=None).fill_null(mask),\n",
    "        pl.col('subcategory').list.eval(pl.element().replace(subcategory['subcategory'], subcategory['index'], default=None)).list.drop_nulls(),\n",
    "        pl.col('premium').cast(pl.Int8)\n",
    ")\n",
    "\n",
    "dummies_topics = articles.select('article_id', 'topics').explode('topics').drop_nulls().to_dummies(columns=['topics'])\\\n",
    "    .group_by('article_id').agg(pl.all().sum())\n",
    "dummies_subcategories = articles.select('article_id', 'subcategory').explode('subcategory').drop_nulls().to_dummies(columns=['subcategory'])\n",
    "\n",
    "articles = articles.join(dummies_topics, on='article_id', how='left')\\\n",
    "    .join(dummies_subcategories, on='article_id', how='left')\\\n",
    "    .drop('topics', 'subcategory')\n",
    "    \n",
    "one_hot_cols = [col for col in articles.columns if col.startswith('topics_') or col.startswith('subcategory_')]\n",
    "articles = articles.with_columns(\n",
    "    pl.col(one_hot_cols).fill_null(0)\n",
    ")\n",
    "\n",
    "df = pl.concat([\n",
    "    slice.explode(pl.all().exclude('user_id'))\\\n",
    "        .with_columns(\n",
    "            pl.col('scroll_percentage_fixed').fill_null(0.),\n",
    "            pl.col('read_time_fixed').fill_null(0.),\n",
    "        )\\\n",
    "        .with_columns(\n",
    "            (pl.col('impression_time_fixed').dt.hour() // 4).alias('hour_group'),\n",
    "            pl.col('impression_time_fixed').dt.weekday().alias('weekday'),\n",
    "        ).drop('impression_time_fixed')\\\n",
    "        .rename({'scroll_percentage_fixed': 'scroll_percentage', 'read_time_fixed': 'read_time'})\n",
    "        .join(articles, left_on='article_id_fixed', right_on='article_id', how='left').drop('article_id_fixed')\\\n",
    "        .group_by('user_id').agg(pl.all())\n",
    "    for slice in history.iter_slices(10000)\n",
    "])\n",
    "\n",
    "cols = df.columns\n",
    "topics_cols = sorted([col for col in cols if col.startswith('topics_')], key=lambda x: int(x.split('_')[-1]))\n",
    "subcategory_cols = sorted([col for col in cols if col.startswith('subcategory_')], key=lambda x: int(x.split('_')[-1]))\n",
    "all_others = set(cols) - set(topics_cols) - set(subcategory_cols) - {'user_id'}\n",
    "cols = ['user_id'] + list(all_others) + topics_cols + subcategory_cols\n",
    "df = df.select(cols)\n",
    "df = reduce_polars_df_memory_size(df)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def build_sequences_seq_to_one(df: pl.DataFrame, w: int, stride: int):\n",
    "    all_features = df.drop('user_id').columns\n",
    "    singular_cols = ['topics', 'subcategory', 'category', 'weekday', 'hour_group']\n",
    "    name_idx_dict = {key: [i for i, col in enumerate(all_features) if col.startswith(key)] for key in singular_cols}\n",
    "    numerical_cols = ['scroll_percentage', 'read_time', 'premium']\n",
    "    name_idx_dict['numerical'] = [i for i, col in enumerate(all_features) if col in numerical_cols]\n",
    "        \n",
    "    res = {key: ([], []) for key in name_idx_dict.keys()}\n",
    "\n",
    "    for user_df in tqdm(df.partition_by('user_id')):\n",
    "        x = user_df.drop('user_id').to_numpy()[0]\n",
    "        x = np.array([np.array(x_i) for x_i in x])\n",
    "                \n",
    "        i = 0\n",
    "        if i + w >= x.shape[1]:\n",
    "            # in case history is shorter than the window then we pad it and select the last element as target\n",
    "            pad_width = w - x[:, :-1].shape[1]\n",
    "            pad_m = np.zeros((x.shape[0], pad_width))\n",
    "            padded_x = np.concatenate((pad_m, x[:, :-1]), axis=1)\n",
    "            y_i = x[:, -1]\n",
    "            \n",
    "            for key, idx in name_idx_dict.items():\n",
    "                res[key][0].append(padded_x[idx, :].T)\n",
    "                res[key][1].append(y_i[idx].T)\n",
    "            \n",
    "        else:\n",
    "            while i + w < x.shape[1]:\n",
    "                # in case history is larger than the window then we select the window and the target randomly between the next elements\n",
    "                x_i = x[:, i:i+w]\n",
    "                target_random_id = np.random.randint(i+w, x.shape[1])\n",
    "                y_i = x[:, target_random_id]\n",
    "                \n",
    "                for key, idx in name_idx_dict.items():\n",
    "                    res[key][0].append(x_i[idx, :].T)\n",
    "                    res[key][1].append(y_i[idx].T)\n",
    "                \n",
    "                i+=stride\n",
    "                         \n",
    "            #TODO: add padding for the last sequence, if we want to keep it\n",
    "                \n",
    "\n",
    "    for key in res.keys():\n",
    "        res[key] = (np.array(res[key][0]), np.array(res[key][1]))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 147.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5863, 20, 78)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = build_sequences_seq_to_one(df[:100], w=20, stride=5)\n",
    "train_data['topics'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polimi.utils.tf_models import TemporalHistorySequenceModel, TemporalHistoryClassificationModel\n",
    "from polimi.utils._polars import reduce_polars_df_memory_size\n",
    "\n",
    "model = TemporalHistorySequenceModel(\n",
    "    seq_embedding_dims={\n",
    "        # adding, for the moment, one dim more to cover missings in non one-hot vectors\n",
    "        'topics': (78, 10, True),\n",
    "        'subcategory': (174, 10, True),\n",
    "        'category': (26, 10, False),\n",
    "        'weekday': (8, 3, False),\n",
    "        'hour_group': (7, 3, False),\n",
    "    },\n",
    "    seq_numerical_features=['scroll_percentage', 'read_time', 'premium'],\n",
    "    n_recurrent_layers=1,\n",
    "    recurrent_embedding_dim=64,\n",
    "    l1_lambda=1e-4,\n",
    "    l2_lambda=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 5.4941\n",
      "Epoch 2/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.7585\n",
      "Epoch 3/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 4.6179\n",
      "Epoch 4/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.5613\n",
      "Epoch 5/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.5797\n",
      "Epoch 6/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 4.5396\n",
      "Epoch 7/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.3560\n",
      "Epoch 8/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.0833\n",
      "Epoch 9/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 4.2371\n",
      "Epoch 10/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 4.2991\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds=train_data,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    # target for (topics, subcategory, category)\n",
    "    loss=[tfk.losses.BinaryCrossentropy(), tfk.losses.BinaryCrossentropy(), tfk.losses.CategoricalCrossentropy()],\n",
    "    loss_weights=[0.5, 0.1, 0.4],\n",
    "    optimizer=tfk.optimizers.Adam(learning_rate=1e-4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
