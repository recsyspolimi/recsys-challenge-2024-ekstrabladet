import polars as pl
import pandas as pd
import os
import json
import numpy as np
from catboost import CatBoostClassifier, CatBoostRanker, Pool, sum_models
import gc
from ebrec.evaluation.metrics_protocols import *
from fastauc.fastauc.fast_auc import CppAuc
import argparse
from polimi.utils._polars import reduce_polars_df_memory_size, inflate_polars_df


## IMPORTANT: This script is used to train the CatBoost Ranker model using the batches generated by the script generate_splits.py
## Change the paths accordingly to the location of the preprocessed datasets

# Flag that specifies if the model is trained with the train and validation datasets
TRAIN_VAL = True

# Number of batches to train the model
N_BATCH = 10

# Path to the preprocessed datasets
dataset_path = '/home/ubuntu/experiments/preprocessing_train_new_with_recsys'

# Path to the preprocessed validation datasets
validation_path = '/home/ubuntu/experiments/preprocessing_val_new_with_recsys'

# Path to the batches
batch_split_directory = '/home/ubuntu/experiments/catboost_rnk_recsys_train_val/batches'

# Path to save the model
model_path = '/home/ubuntu/experiments/catboost_rnk_recsys_train_val/models'

# Flag that specifies if the model is a ranker or a classifier
RANKER = True

# CatBoost parameters
catboost_params = {
    "iterations": 2421,
    "learning_rate": 0.061372161824290145,
    "rsm": 0.681769606695633,
    "reg_lambda": 0.4953354255208565,
    "grow_policy": "SymmetricTree",
    "bootstrap_type": "MVS",
    "subsample": 0.5108219602277233,
    "random_strength": 14.089062269780399,
    "fold_permutation_block": 39,
    "border_count": 34,
    "sampling_frequency": "PerTreeLevel",
    "score_function": "Cosine",
    "depth": 8,
    "mvs_reg": 0.0015341832942953422
}



def load_batch(dataset_path, batch_split_directory, batch_index):

    train_ds = pl.scan_parquet(dataset_path + '/train_ds.parquet')

    if TRAIN_VAL:
        val_ds = pl.scan_parquet(validation_path + '/validation_ds.parquet')
    batch = pl.scan_parquet(batch_split_directory +
                            f'/batch_{batch_index}.parquet').collect()

    subsampled_train = train_ds.filter(pl.col('impression_id').is_in(
        batch.select('impression_id'))).collect()
    columns = subsampled_train.columns
    
    del train_ds
    gc.collect()

    if TRAIN_VAL:
        subsampled_val = val_ds.filter(pl.col('impression_id').is_in(
            batch.select('impression_id'))).select(columns).collect()
        subsampled_train = inflate_polars_df(subsampled_train)
        subsampled_train = reduce_polars_df_memory_size(subsampled_train.vstack(inflate_polars_df(subsampled_val)))
        del subsampled_val
        gc.collect()
    with open(os.path.join(dataset_path, 'data_info.json')) as data_info_file:
        data_info = json.load(data_info_file)
    
    if RANKER:
        order = subsampled_train.select(['impression_id','article','user_id']).sort(by = 'impression_id')
        subsampled_train = order.join(subsampled_train, on=['impression_id','article','user_id'], how='left')
        groups = subsampled_train.select('impression_id').to_numpy().flatten()    
        
    if 'postcode' in subsampled_train.columns:
        subsampled_train = subsampled_train.with_columns(pl.col('postcode').fill_null(5))
    if 'article_type' in subsampled_train.columns:
        subsampled_train = subsampled_train.with_columns(pl.col('article_type').fill_null('article_default'))
    if 'impression_time' in subsampled_train.columns:
        subsampled_train = subsampled_train.drop(['impression_time'])
    print('ckp 2')
    subsampled_train = subsampled_train.drop(['impression_id', 'article', 'user_id']).to_pandas()
    subsampled_train[data_info['categorical_columns']] = subsampled_train[data_info['categorical_columns']].astype('category')
    print('ckp 3')
    X = subsampled_train.drop(columns=['target'])
    y = subsampled_train['target']
    
    print(X.shape)

    if 'impression_time' in X:
        X = X.drop(['impression_time'])

    del batch, subsampled_train
    gc.collect()

    if RANKER:
        return X, y, groups
    else:
        return X, y


def train_single_batch(batch, model_path, catboost_params, data_info, dataset_path, batch_split_directory, RANKER):
    print(f'-------------BATCH {batch}-----------')
    output_dir = model_path + f'/model_{batch}.cbm'
    if RANKER:
        model = CatBoostRanker(
            **catboost_params, cat_features=data_info['categorical_columns'])
    else:
        model = CatBoostClassifier(
            **catboost_params, cat_features=data_info['categorical_columns'])

    print(f'Collecting batch...')
    if RANKER:
        X, y, groups = load_batch(dataset_path, batch_split_directory, batch)
        print('Fitting Model...')
        model.fit(X, y, group_id=groups, verbose=20)
    else :
        X, y = load_batch(dataset_path, batch_split_directory, batch)
        print('Fitting Model...')
        model.fit(X, y, group_id=groups, verbose=20)
        
    model.save_model(output_dir)
    del model, X, y, groups
    gc.collect()


def batch_training(model_path, catboost_params, data_info, dataset_path, batch_split_directory, RANKER):

    for batch in range(N_BATCH):
        train_single_batch(batch, model_path, catboost_params, data_info, dataset_path, batch_split_directory, RANKER)

    models = []
    for batch in range(N_BATCH):
        if RANKER:
            model = CatBoostRanker(
                **catboost_params, cat_features=data_info['categorical_columns'])
        else:
            model = CatBoostClassifier(
                **catboost_params, cat_features=data_info['categorical_columns'])

        model.load_model(model_path + f'/model_{batch}.cbm', format='cbm')
        models.append(model)
    weights = [1/N_BATCH] * N_BATCH

    model = sum_models(models, weights=weights,
                       ctr_merge_policy='IntersectingCountersAverage')

    return model


if __name__ == '__main__':
    
    with open(os.path.join(dataset_path, 'data_info.json')) as data_info_file:
        data_info = json.load(data_info_file)

    print(f'Data info: {data_info}')

    print(f'Starting to train the catboost model')
    
    batch_training(model_path, catboost_params, data_info, dataset_path, batch_split_directory, RANKER)
   