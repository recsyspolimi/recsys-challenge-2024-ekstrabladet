{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from polimi.utils._inference import _inference\n",
    "from ebrec.evaluation.metrics_protocols import *\n",
    "from ebrec.utils._behaviors import sampling_strategy_wu2019\n",
    "from polimi.utils._polars import reduce_polars_df_memory_size\n",
    "from polimi.test.level_2_ensemble.build_model_predictions import require_subsampled_set, train_predict_model\n",
    "from fastauc.fastauc.fast_auc import CppAuc\n",
    "import os\n",
    "import logging\n",
    "from lightgbm import LGBMClassifier, LGBMRanker\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing_extensions import List, Tuple, Dict, Type\n",
    "import polars as pl\n",
    "from polimi.utils._tuning_params import get_models_params\n",
    "import gc\n",
    "from polars import testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BOOSTERS = 20\n",
    "params = {\n",
    "         \"n_estimators\": 600,\n",
    "          \"max_depth\": 5, \n",
    "          \"num_leaves\": 255,\n",
    "          \"subsample_freq\": 4,\n",
    "          \"subsample\": 0.6004099528013062, \n",
    "          \"learning_rate\": 0.020058747735265076, \n",
    "          \"colsample_bytree\": 0.28816104133228293, \n",
    "          \"colsample_bynode\": 0.9436687124253154,\n",
    "          \"reg_lambda\": 0.0009096841984127709, \n",
    "          \"reg_alpha\": 0.00229692020127837, \n",
    "          \"min_split_gain\": 0.06569239337571059, \n",
    "          \"min_child_weight\": 0.0025913515338086167, \n",
    "          \"min_child_samples\": 53, \n",
    "          \"extra_trees\": True, \n",
    "          \"max_bin\": 8,\n",
    "          \"verbosity\": -1,\n",
    "        }\n",
    "cpp_auc = CppAuc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/ubuntu/experiments/stacking/sub_pred_icm'\n",
    "train_ds = pl.read_parquet('/home/ubuntu/experiments/stacking/sub_pred_icm/train_ds.parquet')\n",
    "val_ds = pl.read_parquet('/home/ubuntu/experiments/stacking/pred_icm/validation_ds.parquet')\n",
    "with open(os.path.join(dataset_path, 'data_info.json')) as data_info_file:\n",
    "        data_info = json.load(data_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (298_335, 231)\n",
      "┌────────────┬─────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ impression ┆ article ┆ predictio ┆ predictio ┆ … ┆ roberta_e ┆ w_2_vec_e ┆ emotions_ ┆ constrast │\n",
      "│ _id        ┆ ---     ┆ n_catboos ┆ n_catboos ┆   ┆ mb_icm_mi ┆ mb_icm_mi ┆ emb_icm_m ┆ ive_emb_i │\n",
      "│ ---        ┆ i32     ┆ t_ranker  ┆ t_classif ┆   ┆ nus_media ┆ nus_media ┆ inus_medi ┆ cm_minus_ │\n",
      "│ u32        ┆         ┆ ---       ┆ ier       ┆   ┆ n_a…      ┆ n_a…      ┆ an_…      ┆ med…      │\n",
      "│            ┆         ┆ f32       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│            ┆         ┆           ┆ f32       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ f32       │\n",
      "╞════════════╪═════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 157014     ┆ 9776223 ┆ 0.138048  ┆ 0.181434  ┆ … ┆ -0.923473 ┆ 0.003323  ┆ -2.5146e- ┆ -0.001344 │\n",
      "│            ┆         ┆           ┆           ┆   ┆           ┆           ┆ 8         ┆           │\n",
      "│ 157014     ┆ 9776438 ┆ 0.359669  ┆ 0.3867    ┆ … ┆ -4.615771 ┆ -0.0064   ┆ -0.00266  ┆ -0.00364  │\n",
      "│ 157014     ┆ 9776442 ┆ 0.468283  ┆ 0.416019  ┆ … ┆ -1.84677  ┆ 0.001635  ┆ -0.010637 ┆ 0.003509  │\n",
      "│ 157016     ┆ 9776322 ┆ 1.014783  ┆ 0.564579  ┆ … ┆ -3.693848 ┆ -0.003286 ┆ -0.015957 ┆ -0.003322 │\n",
      "│ 157016     ┆ 9220931 ┆ -3.618523 ┆ 0.004424  ┆ … ┆ 0.0       ┆ 0.0       ┆ -0.009308 ┆ 0.0       │\n",
      "│ …          ┆ …       ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
      "│ 580037082  ┆ 9775701 ┆ -1.959689 ┆ 0.0797    ┆ … ┆ -3.693192 ┆ -0.001572 ┆ -0.009308 ┆ -0.001019 │\n",
      "│ 580037082  ┆ 9775621 ┆ 0.111738  ┆ 0.104276  ┆ … ┆ -0.923281 ┆ 0.001695  ┆ -0.002659 ┆ -0.000951 │\n",
      "│ 580037121  ┆ 9775648 ┆ 2.226808  ┆ 0.738118  ┆ … ┆ 1.846999  ┆ 0.001646  ┆ 0.014627  ┆ 0.001524  │\n",
      "│ 580037121  ┆ 9775722 ┆ 0.357859  ┆ 0.200962  ┆ … ┆ 6.464156  ┆ 0.009745  ┆ 0.014626  ┆ 0.003601  │\n",
      "│ 580037121  ┆ 9775701 ┆ 1.711408  ┆ 0.594385  ┆ … ┆ 6.463403  ┆ 0.00946   ┆ 0.022605  ┆ 0.007068  │\n",
      "└────────────┴─────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "if 'postcode' in train_ds.columns:\n",
    "    train_ds = train_ds.with_columns(pl.col('postcode').fill_null(5))\n",
    "if 'article_type' in train_ds.columns:\n",
    "    train_ds = train_ds.with_columns(pl.col('article_type').fill_null('article_default'))\n",
    "if 'impression_time' in train_ds.columns:\n",
    "    train_ds = train_ds.drop(['impression_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_pandas = train_ds.drop(['impression_id','article','user_id']).to_pandas()\n",
    "train_ds_pandas[data_info['categorical_columns']] = train_ds_pandas[data_info['categorical_columns']].astype('category')\n",
    "X = train_ds_pandas.drop(columns=['target'])\n",
    "y = train_ds_pandas['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199078/242159418.py:6: DeprecationWarning: named `columns` param is deprecated; use positional `*args` instead.\n",
      "  val_ds = val_ds.drop(columns = ['impression_time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Baseline AUC: 0.8223259084374449\n"
     ]
    }
   ],
   "source": [
    "if 'postcode' in val_ds.columns:\n",
    "        val_ds = val_ds.with_columns(pl.col('postcode').fill_null(5))\n",
    "if 'article_type' in val_ds.columns:\n",
    "        val_ds = val_ds.with_columns(pl.col('article_type').fill_null('article_default'))  \n",
    "if 'impression_time' in val_ds.columns:\n",
    "        val_ds = val_ds.drop(columns = ['impression_time']) \n",
    "        \n",
    "val_ds = val_ds.to_pandas()\n",
    "val_ds[data_info['categorical_columns']] = val_ds[data_info['categorical_columns']].astype('category')\n",
    "\n",
    "X_val = val_ds[X.columns]\n",
    "evaluation_ds = pl.from_pandas(val_ds[['impression_id','article', 'target']])\n",
    "\n",
    "print('Baseline')\n",
    "model = LGBMClassifier(**params)\n",
    "model.fit(X, y)\n",
    "evaluation_ds_copy = evaluation_ds\n",
    "evaluation_ds_copy = evaluation_ds_copy.with_columns(pl.Series(model.predict_proba(X_val)[:,1]).alias('prediction')).group_by('impression_id').agg(pl.col('target'), pl.col('prediction'))\n",
    "result = np.mean(\n",
    "        [cpp_auc.roc_auc_score(np.array(y_t).astype(bool), np.array(y_s).astype(np.float32)) \n",
    "            for y_t, y_s in zip(evaluation_ds_copy['target'].to_list(), \n",
    "                                evaluation_ds_copy['prediction'].to_list())]\n",
    "    )\n",
    "print(f'Baseline AUC: {result}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1/train_ds.shape[0]]*train_ds.shape[0]\n",
    "train_ds = train_ds.with_columns(pl.Series(weights).alias('weight'))\n",
    "models = []\n",
    "models_weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_booster(models_list, models_weights, X_val, evaluation_ds):\n",
    "    n_models = len(models_list)\n",
    "    remap = {\n",
    "        0:-1,\n",
    "        1:1\n",
    "    }\n",
    "    demap={\n",
    "        -1:0,\n",
    "        1:1\n",
    "    }\n",
    "    evaluation_ds_copy = evaluation_ds\n",
    "    for n_model in range(n_models):\n",
    "        evaluation_ds_copy = evaluation_ds_copy.with_columns(pl.Series(models_list[n_model].predict_proba(X_val)[:,1]).alias(f'prediction_{n_model}'))\\\n",
    "            .with_columns((pl.col(f'prediction_{n_model}')* models_weights[n_model]).alias(f'prediction_{n_model}'))\n",
    "    prediction_ds = evaluation_ds_copy.with_columns(pl.sum_horizontal([f'prediction_{n_model}' for n_model in range(n_models)]).alias('prediction'))\\\n",
    "        .drop([f'prediction_{n_model}' for n_model in range(n_models)])\n",
    "    evaluation_ds_copy = evaluation_ds_copy.with_columns(pl.Series(prediction_ds['prediction']).alias('prediction'))\\\n",
    "        .group_by('impression_id').agg(pl.col('target'), pl.col('prediction'))\n",
    "    \n",
    "    result = np.mean(\n",
    "        [cpp_auc.roc_auc_score(np.array(y_t).astype(bool), np.array(y_s).astype(np.float32)) \n",
    "            for y_t, y_s in zip(evaluation_ds_copy['target'].to_list(), \n",
    "                                evaluation_ds_copy['prediction'].to_list())]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # for n_model in range(n_models):\n",
    "    #     evaluation_ds_copy = evaluation_ds_copy.with_columns(pl.Series(models_list[n_model].predict_proba(X_val)[:,1]).alias(f'prediction_{n_model}'))\\\n",
    "    #         .with_columns(pl.col(f'prediction_{n_model}').replace(remap))\\\n",
    "    #         .with_columns((pl.col(f'prediction_{n_model}')* models_weights[n_model]).alias(f'prediction_{n_model}'))\n",
    "    # prediction_ds = evaluation_ds_copy.with_columns(pl.sum_horizontal([f'prediction_{n_model}' for n_model in range(n_models)]).alias('prediction'))\\\n",
    "    #     .drop([f'prediction_{n_model}' for n_model in range(n_models)])\n",
    "    # evaluation_ds_copy = evaluation_ds_copy.with_columns(pl.Series(prediction_ds['prediction']).sign().alias('prediction'))\\\n",
    "    #     .with_columns(pl.col('prediction').replace(demap))\\\n",
    "    #     .group_by('impression_id').agg(pl.col('target'), pl.col('prediction'))\n",
    "    \n",
    "    # result = np.mean(\n",
    "    #     [cpp_auc.roc_auc_score(np.array(y_t).astype(bool), np.array(y_s).astype(np.float32)) \n",
    "    #         for y_t, y_s in zip(evaluation_ds_copy['target'].to_list(), \n",
    "    #                             evaluation_ds_copy['prediction'].to_list())]\n",
    "    # )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Fitting model 0...\n",
      "Mama patience is 5\n",
      "error : 0.2127909899944693\n",
      "AUC val: 0.8221738249946411\n",
      "---------------------------------\n",
      "Fitting model 1...\n",
      "Mama patience is 5\n",
      "error : 0.3251853367430857\n",
      "AUC val: 0.8212849997370197\n",
      "---------------------------------\n",
      "Fitting model 2...\n",
      "Mama patience is 4\n",
      "error : 0.38827530533655197\n",
      "AUC val: 0.8215463910131302\n",
      "---------------------------------\n",
      "Fitting model 3...\n",
      "Mama patience is 3\n",
      "error : 0.4114394459987322\n",
      "AUC val: 0.821047885807885\n",
      "---------------------------------\n",
      "Fitting model 4...\n",
      "Mama patience is 2\n",
      "error : 0.4225632443244527\n",
      "AUC val: 0.8213156432268337\n",
      "---------------------------------\n",
      "Fitting model 5...\n",
      "Mama patience is 1\n",
      "error : 0.425258592253537\n",
      "AUC val: 0.8209208656260508\n",
      "Mama is angry now, she has no more patience\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "MAX_PATIENCE = 5\n",
    "train_ds = train_ds.with_columns(pl.Series(np.arange(train_ds.shape[0])).alias('index'))\n",
    "patience = MAX_PATIENCE\n",
    "last_best = 0\n",
    "for i in range(N_BOOSTERS):\n",
    "    print('---------------------------------')\n",
    "    print(f'Fitting model {i}...')\n",
    "    print(f'Mama patience is {patience}')\n",
    "    sampled_items = np.random.choice(train_ds['index'].to_list(), size=int(train_ds.shape[0]*0.3), p=train_ds['weight'].to_list())\n",
    "    if 'prediction' in train_ds.columns:\n",
    "        train_ds = train_ds.drop('prediction')\n",
    "    sampled_items = pl.from_numpy(sampled_items, schema = ['index'])\n",
    "    x_train = sampled_items.join(train_ds, on='index').drop(['index','weight','impression_id','article','user_id']).to_pandas()\n",
    "    x_train[data_info['categorical_columns']] = x_train[data_info['categorical_columns']].astype('category')\n",
    "    y_train = x_train['target']\n",
    "    x_train = x_train[X.columns]\n",
    "    # x_train = train_ds.filter(pl.col('index').is_in(sampled_items)).drop(['index','weight','target','impression_id','article','user_id'])\n",
    "    # y_train = train_ds.filter(pl.col('index').is_in(sampled_items))['target']\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(x_train, y_train)\n",
    "    train_ds = train_ds.with_columns(pl.Series(model.predict(X)).alias('prediction'))\n",
    "    error = train_ds.filter(pl.col('prediction') != pl.col('target')).select('weight').sum().item()\n",
    "    print(f'error : {error}')\n",
    "    if error == 0:\n",
    "        break\n",
    "    if error < 0.5:\n",
    "        r_error = ((1-error)/error)\n",
    "        alpha = math.log(r_error) * 0.5\n",
    "        pos_corr = math.exp(-alpha)\n",
    "        neg_corr = math.exp(alpha)\n",
    "        train_ds = train_ds.with_columns(pl.when(pl.col('prediction') != pl.col('target'))\\\n",
    "            .then(pl.col('weight') * neg_corr)\\\n",
    "                .otherwise(pl.col('weight')* pos_corr).alias('new_weight'))\n",
    "        train_ds = train_ds.drop('weight').rename({'new_weight' : 'weight'})\\\n",
    "            .with_columns(pl.col('weight')/pl.col('weight').sum())\n",
    "        models.append(model)\n",
    "        models_weights.append(alpha)\n",
    "        evaluation = eval_booster(models, models_weights, X_val, evaluation_ds)\n",
    "        print(f'AUC val: {evaluation}')\n",
    "        patience -= 1\n",
    "        if last_best < evaluation:\n",
    "            last_best = evaluation\n",
    "            patience = MAX_PATIENCE\n",
    "        else :\n",
    "            if patience == 0:\n",
    "                print('Mama is angry now, she has no more patience')\n",
    "                break\n",
    "        results.append(evaluation)\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print('Mama is angry now, she has no more patience')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8221738249946411, 0.8212849997370197, 0.8215463910131302, 0.821047885807885, 0.8213156432268337]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
